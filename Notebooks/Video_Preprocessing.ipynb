{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b478796",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3c5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d82a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(\"dataset/raw_data\") \n",
    "# output_path = os.path.join(\"dataset/preprocess_data\")\n",
    "\n",
    "# Actions that we try to detect\n",
    "words = np.array(['hello', 'like', 'dislike'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba25d941",
   "metadata": {},
   "source": [
    "## Resize and flip videos and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12308969",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(['hello', 'like', 'dislike'])\n",
    "input_path = os.path.join(\"dataset/raw_data\") \n",
    "output_path = os.path.join(\"dataset/preprocess_data\")\n",
    "\n",
    "for word in words:  \n",
    "    a = 0\n",
    "    for video_file in glob(os.path.join(input_path, word, \"*\")):\n",
    "        \n",
    "        result_flip = cv.VideoWriter(f'{output_path}/{word}/flip_{a}.mp4', \n",
    "                         cv.VideoWriter_fourcc(*'MP4V'),\n",
    "                         10, (400,600))\n",
    "        result = cv.VideoWriter(f'{output_path}/{word}/resize_{a}.mp4', \n",
    "                         cv.VideoWriter_fourcc(*'MP4V'),\n",
    "                         10, (400,600))\n",
    "        \n",
    "        cap = cv.VideoCapture(video_file)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            \n",
    "            ret, image = cap.read()\n",
    "            if ret == True:\n",
    "                \n",
    "                img_resize = cv.resize(image, (640, 480))\n",
    "                img_flip = cv.flip(img_resize,1)\n",
    "                \n",
    "                result.write(img_resize)\n",
    "                result_flip.write(img_flip)\n",
    "#                 cv.imshow('frame',resize)\n",
    "#                 if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "            else:\n",
    "                break\n",
    "        a += 1\n",
    "\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41b226a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5245a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\mslr\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.64.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ad7c38",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d54a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from glob import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ace28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a382ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc242a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "        mp_drawing_styles.get_default_hand_landmarks_style(), mp_drawing_styles.get_default_hand_connections_style())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec423fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    keypoints = []\n",
    "    if results.multi_hand_landmarks:\n",
    "        for h_lmk in results.multi_hand_landmarks[0].landmark:\n",
    "            keypoints.append(np.array([h_lmk.x, h_lmk.y, h_lmk.z]))\n",
    "    else:\n",
    "        keypoints.append(np.zeros(21*3))\n",
    "    \n",
    "    keypoints = np.array(keypoints).flatten()\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6102598",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'dataset/custom_raw_data/bro_alex_401_450/'\n",
    "output_path = 'dataset/custom_numpy/'\n",
    "\n",
    "with mp_hands.Hands( static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
    "    for video_folder in os.listdir(data_path):\n",
    "        for video_file in os.listdir(f'{data_path}/{video_folder}'):\n",
    "            cap = cv.VideoCapture(f'{data_path}/{video_folder}/{video_file}')\n",
    "            video_file_name = video_file.split('.')[0]\n",
    "            if not os.path.exists(f'{output_path}/{video_folder}/{video_file_name}'):\n",
    "                os.makedirs(os.path.join(f'{output_path}/{video_folder}/{video_file_name}'))\n",
    "\n",
    "            num = 1\n",
    "            while cap.isOpened():\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                if ret is False:\n",
    "                    break\n",
    "\n",
    "                frame = cv.resize(frame, (640,480))\n",
    "                img, results = mediapipe_detection(frame, hands)\n",
    "\n",
    "                if not results.multi_hand_landmarks:\n",
    "                    continue\n",
    "\n",
    "                draw_landmarks(img, results)\n",
    "\n",
    "#                 cv.imshow('Detect landmarks', img)\n",
    "\n",
    "                keypoints = extract_keypoints(results)         \n",
    "                npy_path = os.path.join(f'{output_path}/{video_folder}/{video_file_name}/{num}')\n",
    "                np.save(npy_path, keypoints)\n",
    "            \n",
    "                num+=1\n",
    "                                   \n",
    "#                 if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "# #     print(keypoints)\n",
    "#     cap.release()\n",
    "#     cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d3bb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be4ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
